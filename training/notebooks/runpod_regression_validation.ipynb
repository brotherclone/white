{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 4: Regression Training Validation (Task 8.5)\n",
    "## January 27, 2023 11:40 AM\n",
    "\n",
    "Validates regression model convergence using pre-computed DeBERTa embeddings.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Upload `training_data_with_embeddings.parquet` to `/workspace/data/`\n",
    "- RunPod GPU instance with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/upgrade dependencies - typing_extensions first to avoid import errors\n",
    "!pip install -q --upgrade typing_extensions\n",
    "!pip install -q torch pandas pyarrow scikit-learn scipy tqdm wandb matplotlib seaborn\n",
    "\n",
    "# NOTE: If you get import errors after running this cell, restart the kernel and run again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Initialize wandb\n",
    "USE_WANDB = True\n",
    "\n",
    "if USE_WANDB:\n",
    "    import wandb\n",
    "    wandb.init(\n",
    "        project=\"white-regression-validation\",\n",
    "        name=\"phase4-regression-convergence\",\n",
    "        tags=[\"phase4\", \"regression\", \"runpod\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"data\": {\n",
    "        \"parquet_path\": \"/workspace/data/training_data_with_embeddings.parquet\",\n",
    "        \"embedding_column\": \"embedding\",\n",
    "        \"label_smoothing\": 0.1,\n",
    "        \"train_split\": 0.8,\n",
    "        \"random_seed\": 42,\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"embedding_dim\": 768,\n",
    "        \"hidden_dims\": [256, 128],\n",
    "        \"dropout\": 0.3,\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 30,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"weight_decay\": 1e-4,\n",
    "        \"early_stopping_patience\": 7,\n",
    "        \"loss_weights\": {\n",
    "            \"temporal\": 1.0,\n",
    "            \"spatial\": 1.0,\n",
    "            \"ontological\": 1.0,\n",
    "            \"confidence\": 0.5,\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading data from {CONFIG['data']['parquet_path']}...\")\n",
    "df = pd.read_parquet(CONFIG['data']['parquet_path'])\n",
    "print(f\"Loaded {len(df)} segments with embeddings\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check embedding shape\n",
    "sample_emb = df['embedding'].iloc[0]\n",
    "if isinstance(sample_emb, list):\n",
    "    sample_emb = np.array(sample_emb)\n",
    "print(f\"Embedding shape: {sample_emb.shape}\")\n",
    "print(f\"Embedding dtype: {sample_emb.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Rainbow Table distribution\n",
    "print(\"\\nRainbow Table Distribution:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for col in ['rainbow_color_temporal_mode', 'rainbow_color_objectional_mode', 'rainbow_color_ontological_mode']:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Target Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftTargetGenerator:\n",
    "    \"\"\"Converts discrete Rainbow Table labels to continuous regression targets.\"\"\"\n",
    "\n",
    "    TEMPORAL_MODES = [\"Past\", \"Present\", \"Future\"]\n",
    "    SPATIAL_MODES = [\"Thing\", \"Place\", \"Person\"]\n",
    "    ONTOLOGICAL_MODES = [\"Imagined\", \"Forgotten\", \"Known\"]\n",
    "\n",
    "    def __init__(self, label_smoothing: float = 0.1):\n",
    "        self.smoothing = label_smoothing\n",
    "\n",
    "    def to_soft_target(self, label: str, mode_list: List[str]) -> np.ndarray:\n",
    "        \"\"\"Convert discrete label to smoothed soft target.\"\"\"\n",
    "        if label is None or pd.isna(label) or str(label) == \"None\":\n",
    "            return np.array([1 / 3, 1 / 3, 1 / 3])\n",
    "\n",
    "        target = np.zeros(len(mode_list))\n",
    "        try:\n",
    "            idx = mode_list.index(str(label))\n",
    "            target[idx] = 1.0\n",
    "        except ValueError:\n",
    "            return np.array([1 / len(mode_list)] * len(mode_list))\n",
    "\n",
    "        smoothed = (1 - self.smoothing) * target + self.smoothing * (1 / len(mode_list))\n",
    "        return smoothed\n",
    "\n",
    "    def generate_targets(self, row: pd.Series) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Generate all regression targets for a segment.\"\"\"\n",
    "        temporal_label = row.get(\"rainbow_color_temporal_mode\")\n",
    "        spatial_label = row.get(\"rainbow_color_objectional_mode\")\n",
    "        ontological_label = row.get(\"rainbow_color_ontological_mode\")\n",
    "\n",
    "        temporal = self.to_soft_target(temporal_label, self.TEMPORAL_MODES)\n",
    "        spatial = self.to_soft_target(spatial_label, self.SPATIAL_MODES)\n",
    "        ontological = self.to_soft_target(ontological_label, self.ONTOLOGICAL_MODES)\n",
    "\n",
    "        is_black = all(\n",
    "            pd.isna(x) or x is None or str(x) == \"None\"\n",
    "            for x in [temporal_label, spatial_label, ontological_label]\n",
    "        )\n",
    "        confidence = np.array([0.0 if is_black else 1.0])\n",
    "\n",
    "        return {\n",
    "            \"temporal\": temporal,\n",
    "            \"spatial\": spatial,\n",
    "            \"ontological\": ontological,\n",
    "            \"confidence\": confidence,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingRegressionDataset(Dataset):\n",
    "    \"\"\"Dataset using pre-computed embeddings for regression training.\"\"\"\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame, embedding_col: str, label_smoothing: float = 0.1):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.embedding_col = embedding_col\n",
    "        self.target_generator = SoftTargetGenerator(label_smoothing)\n",
    "\n",
    "        # Pre-compute all targets for efficiency\n",
    "        print(\"Pre-computing soft targets...\")\n",
    "        self.targets = [\n",
    "            self.target_generator.generate_targets(self.df.iloc[i])\n",
    "            for i in tqdm(range(len(self.df)), desc=\"Generating targets\")\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        embedding = row[self.embedding_col]\n",
    "\n",
    "        if isinstance(embedding, list):\n",
    "            embedding = np.array(embedding)\n",
    "\n",
    "        targets = self.targets[idx]\n",
    "\n",
    "        return {\n",
    "            \"embedding\": torch.tensor(embedding, dtype=torch.float32),\n",
    "            \"temporal_target\": torch.tensor(targets[\"temporal\"], dtype=torch.float32),\n",
    "            \"spatial_target\": torch.tensor(targets[\"spatial\"], dtype=torch.float32),\n",
    "            \"ontological_target\": torch.tensor(targets[\"ontological\"], dtype=torch.float32),\n",
    "            \"confidence_target\": torch.tensor(targets[\"confidence\"], dtype=torch.float32),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RainbowRegressionHead(nn.Module):\n",
    "    \"\"\"Regression head for Rainbow Table ontological mode prediction.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int = 768,\n",
    "        hidden_dims: List[int] = [256, 128],\n",
    "        dropout: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Shared layers\n",
    "        layers = []\n",
    "        in_dim = embedding_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "            ])\n",
    "            in_dim = hidden_dim\n",
    "\n",
    "        self.shared = nn.Sequential(*layers)\n",
    "\n",
    "        # Task-specific heads\n",
    "        self.temporal_head = nn.Linear(hidden_dims[-1], 3)\n",
    "        self.spatial_head = nn.Linear(hidden_dims[-1], 3)\n",
    "        self.ontological_head = nn.Linear(hidden_dims[-1], 3)\n",
    "        self.confidence_head = nn.Linear(hidden_dims[-1], 1)\n",
    "\n",
    "    def forward(self, embeddings: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Forward pass returning softmax distributions and confidence.\"\"\"\n",
    "        x = self.shared(embeddings)\n",
    "\n",
    "        return {\n",
    "            \"temporal\": F.softmax(self.temporal_head(x), dim=-1),\n",
    "            \"spatial\": F.softmax(self.spatial_head(x), dim=-1),\n",
    "            \"ontological\": F.softmax(self.ontological_head(x), dim=-1),\n",
    "            \"confidence\": torch.sigmoid(self.confidence_head(x)),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskRegressionLoss(nn.Module):\n",
    "    \"\"\"Combined loss for multi-task regression.\"\"\"\n",
    "\n",
    "    def __init__(self, weights: Dict[str, float]):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "        self.kl_div = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(\n",
    "        self, predictions: Dict[str, torch.Tensor], targets: Dict[str, torch.Tensor]\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        losses = {}\n",
    "\n",
    "        # KL divergence for probability distributions\n",
    "        for dim in [\"temporal\", \"spatial\", \"ontological\"]:\n",
    "            pred_log = predictions[dim].clamp(min=1e-8).log()\n",
    "            losses[dim] = self.kl_div(pred_log, targets[f\"{dim}_target\"])\n",
    "\n",
    "        # BCE for confidence\n",
    "        losses[\"confidence\"] = self.bce(\n",
    "            predictions[\"confidence\"], targets[\"confidence_target\"]\n",
    "        )\n",
    "\n",
    "        # Weighted sum\n",
    "        total = sum(self.weights[k] * v for k, v in losses.items())\n",
    "\n",
    "        return total, losses\n",
    "\n",
    "\n",
    "def compute_metrics(\n",
    "    predictions: Dict[str, torch.Tensor],\n",
    "    targets: Dict[str, torch.Tensor],\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Compute comprehensive regression metrics.\"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    for dim in [\"temporal\", \"spatial\", \"ontological\"]:\n",
    "        pred = predictions[dim].cpu().numpy()\n",
    "        targ = targets[f\"{dim}_target\"].cpu().numpy()\n",
    "\n",
    "        # MAE\n",
    "        metrics[f\"{dim}_mae\"] = mean_absolute_error(targ.flatten(), pred.flatten())\n",
    "\n",
    "        # Mode accuracy (argmax matches)\n",
    "        pred_mode = pred.argmax(axis=1)\n",
    "        targ_mode = targ.argmax(axis=1)\n",
    "        metrics[f\"{dim}_mode_accuracy\"] = (pred_mode == targ_mode).mean()\n",
    "\n",
    "    # Confidence metrics\n",
    "    conf_pred = predictions[\"confidence\"].cpu().numpy().flatten()\n",
    "    conf_targ = targets[\"confidence_target\"].cpu().numpy().flatten()\n",
    "    metrics[\"confidence_mae\"] = mean_absolute_error(conf_targ, conf_pred)\n",
    "\n",
    "    # Album prediction accuracy\n",
    "    pred_temporal = predictions[\"temporal\"].argmax(dim=-1)\n",
    "    pred_spatial = predictions[\"spatial\"].argmax(dim=-1)\n",
    "    pred_ontological = predictions[\"ontological\"].argmax(dim=-1)\n",
    "\n",
    "    targ_temporal = targets[\"temporal_target\"].argmax(dim=-1)\n",
    "    targ_spatial = targets[\"spatial_target\"].argmax(dim=-1)\n",
    "    targ_ontological = targets[\"ontological_target\"].argmax(dim=-1)\n",
    "\n",
    "    correct = (\n",
    "        (pred_temporal == targ_temporal)\n",
    "        & (pred_spatial == targ_spatial)\n",
    "        & (pred_ontological == targ_ontological)\n",
    "    )\n",
    "    metrics[\"album_accuracy\"] = correct.float().mean().item()\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    component_losses = {k: 0 for k in [\"temporal\", \"spatial\", \"ontological\", \"confidence\"]}\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Training\", leave=False):\n",
    "        embeddings = batch[\"embedding\"].to(device)\n",
    "        targets = {k: v.to(device) for k, v in batch.items() if \"target\" in k}\n",
    "\n",
    "        predictions = model(embeddings)\n",
    "        loss, losses = criterion(predictions, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        for k, v in losses.items():\n",
    "            component_losses[k] += v.item()\n",
    "\n",
    "    n_batches = len(loader)\n",
    "    return {\n",
    "        \"train_loss\": total_loss / n_batches,\n",
    "        **{f\"train_{k}_loss\": v / n_batches for k, v in component_losses.items()},\n",
    "    }\n",
    "\n",
    "\n",
    "def validate(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    device: torch.device,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Validate model.\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = {k: [] for k in [\"temporal\", \"spatial\", \"ontological\", \"confidence\"]}\n",
    "    all_targets = {k: [] for k in [\"temporal_target\", \"spatial_target\", \"ontological_target\", \"confidence_target\"]}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            embeddings = batch[\"embedding\"].to(device)\n",
    "            targets = {k: v.to(device) for k, v in batch.items() if \"target\" in k}\n",
    "\n",
    "            predictions = model(embeddings)\n",
    "            loss, _ = criterion(predictions, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            for k in all_preds:\n",
    "                all_preds[k].append(predictions[k])\n",
    "            for k in all_targets:\n",
    "                all_targets[k].append(targets[k])\n",
    "\n",
    "    # Concatenate\n",
    "    preds_cat = {k: torch.cat(v) for k, v in all_preds.items()}\n",
    "    targets_cat = {k: torch.cat(v) for k, v in all_targets.items()}\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = compute_metrics(preds_cat, targets_cat)\n",
    "    metrics[\"val_loss\"] = total_loss / len(loader)\n",
    "\n",
    "    return metrics, preds_cat, targets_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_idx, val_idx = train_test_split(\n",
    "    range(len(df)),\n",
    "    train_size=CONFIG[\"data\"][\"train_split\"],\n",
    "    random_state=CONFIG[\"data\"][\"random_seed\"],\n",
    ")\n",
    "\n",
    "train_df = df.iloc[train_idx]\n",
    "val_df = df.iloc[val_idx]\n",
    "\n",
    "print(f\"Train: {len(train_df)} segments\")\n",
    "print(f\"Val: {len(val_df)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = EmbeddingRegressionDataset(\n",
    "    train_df,\n",
    "    CONFIG[\"data\"][\"embedding_column\"],\n",
    "    CONFIG[\"data\"][\"label_smoothing\"],\n",
    ")\n",
    "val_dataset = EmbeddingRegressionDataset(\n",
    "    val_df,\n",
    "    CONFIG[\"data\"][\"embedding_column\"],\n",
    "    CONFIG[\"data\"][\"label_smoothing\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders (num_workers=0 to avoid multiprocessing issues in Jupyter)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG[\"training\"][\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG[\"training\"][\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RainbowRegressionHead(\n",
    "    embedding_dim=CONFIG[\"model\"][\"embedding_dim\"],\n",
    "    hidden_dims=CONFIG[\"model\"][\"hidden_dims\"],\n",
    "    dropout=CONFIG[\"model\"][\"dropout\"],\n",
    ").to(device)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Setup training\ncriterion = MultiTaskRegressionLoss(CONFIG[\"training\"][\"loss_weights\"])\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=CONFIG[\"training\"][\"learning_rate\"],\n    weight_decay=CONFIG[\"training\"][\"weight_decay\"],\n)\n# Schedule based on album_accuracy (higher is better)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, mode=\"max\", patience=3, factor=0.5\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"TRAINING (early stopping on album_accuracy)\")\nprint(\"=\" * 80)\n\nbest_album_accuracy = 0.0\nbest_metrics = {}\npatience_counter = 0\nhistory = []\n\nfor epoch in range(CONFIG[\"training\"][\"epochs\"]):\n    print(f\"\\nEpoch {epoch + 1}/{CONFIG['training']['epochs']}\")\n\n    # Train\n    train_metrics = train_epoch(model, train_loader, criterion, optimizer, device)\n\n    # Validate\n    val_metrics, val_preds, val_targets = validate(model, val_loader, criterion, device)\n\n    # Combine metrics\n    all_metrics = {**train_metrics, **val_metrics}\n    all_metrics[\"epoch\"] = epoch\n    history.append(all_metrics)\n\n    # Log to wandb\n    if USE_WANDB:\n        wandb.log(all_metrics)\n\n    # Print progress\n    print(f\"  Train Loss: {train_metrics['train_loss']:.4f}\")\n    print(f\"  Val Loss: {val_metrics['val_loss']:.4f}\")\n    print(f\"  Temporal Mode Acc: {val_metrics.get('temporal_mode_accuracy', 0):.3f}\")\n    print(f\"  Spatial Mode Acc: {val_metrics.get('spatial_mode_accuracy', 0):.3f}\")\n    print(f\"  Ontological Mode Acc: {val_metrics.get('ontological_mode_accuracy', 0):.3f}\")\n    print(f\"  Album Accuracy: {val_metrics.get('album_accuracy', 0):.3f}\")\n\n    # Learning rate scheduling based on album accuracy\n    current_album_acc = val_metrics.get(\"album_accuracy\", 0)\n    scheduler.step(current_album_acc)\n\n    # Early stopping based on album accuracy (higher is better)\n    if current_album_acc > best_album_accuracy:\n        best_album_accuracy = current_album_acc\n        best_metrics = val_metrics.copy()\n        patience_counter = 0\n\n        # Save checkpoint\n        torch.save({\n            \"epoch\": epoch,\n            \"model_state_dict\": model.state_dict(),\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"album_accuracy\": best_album_accuracy,\n            \"metrics\": best_metrics,\n            \"config\": CONFIG,\n        }, \"/workspace/output/regression_validation_best.pt\")\n        print(f\"  Saved best model (album_accuracy={best_album_accuracy:.4f})\")\n    else:\n        patience_counter += 1\n        if patience_counter >= CONFIG[\"training\"][\"early_stopping_patience\"]:\n            print(f\"\\nEarly stopping triggered (patience={patience_counter})\")\n            break\n\nprint(f\"\\nBest album accuracy: {best_album_accuracy:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss\n",
    "ax = axes[0, 0]\n",
    "ax.plot([h['train_loss'] for h in history], label='Train')\n",
    "ax.plot([h['val_loss'] for h in history], label='Val')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Training Loss')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Mode Accuracies\n",
    "ax = axes[0, 1]\n",
    "for dim in ['temporal', 'spatial', 'ontological']:\n",
    "    ax.plot([h[f'{dim}_mode_accuracy'] for h in history], label=dim.capitalize())\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Mode Accuracy')\n",
    "ax.set_title('Mode Accuracies')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Album Accuracy\n",
    "ax = axes[1, 0]\n",
    "ax.plot([h['album_accuracy'] for h in history], color='purple')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Album Accuracy')\n",
    "ax.set_title('Album Prediction Accuracy')\n",
    "ax.grid(True)\n",
    "\n",
    "# MAE\n",
    "ax = axes[1, 1]\n",
    "for dim in ['temporal', 'spatial', 'ontological']:\n",
    "    ax.plot([h[f'{dim}_mae'] for h in history], label=dim.capitalize())\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MAE')\n",
    "ax.set_title('Mean Absolute Error')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/workspace/output/regression_training_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 80)\nprint(\"CONVERGENCE ASSESSMENT (Task 8.5)\")\nprint(\"=\" * 80)\n\nprint(f\"\\nBest Album Accuracy: {best_album_accuracy:.4f}\")\nprint(\"\\nBest Metrics:\")\nfor k, v in sorted(best_metrics.items()):\n    if isinstance(v, float):\n        print(f\"  {k}: {v:.4f}\")\n\n# Convergence checks\nprint(\"\\n\" + \"-\" * 40)\nprint(\"CONVERGENCE CHECKS\")\nprint(\"-\" * 40)\n\nconverged = True\nissues = []\n\n# Check mode accuracies\nfor dim in [\"temporal\", \"spatial\", \"ontological\"]:\n    acc = best_metrics.get(f\"{dim}_mode_accuracy\", 0)\n    if acc < 0.5:\n        converged = False\n        issues.append(f\"{dim} mode accuracy ({acc:.3f}) below 0.5\")\n    elif acc < 0.7:\n        issues.append(f\"{dim} mode accuracy ({acc:.3f}) below 0.7 (warn)\")\n\n# Check album accuracy\nif best_album_accuracy < 0.3:\n    converged = False\n    issues.append(f\"Album accuracy ({best_album_accuracy:.3f}) below 0.3\")\nelif best_album_accuracy < 0.7:\n    issues.append(f\"Album accuracy ({best_album_accuracy:.3f}) below 0.7 (warn)\")\n\n# Check loss reduction\nif len(history) > 5:\n    initial_loss = history[0][\"val_loss\"]\n    final_loss = history[-1][\"val_loss\"]\n    reduction = (initial_loss - final_loss) / initial_loss if initial_loss > 0 else 0\n    if reduction < 0.1:\n        issues.append(f\"Loss reduction ({reduction:.1%}) below 10% (info only)\")\n\nprint()\nif converged and not issues:\n    print(\"CONVERGENCE VALIDATED - Model training successful!\")\nelif converged:\n    print(\"CONVERGENCE WITH WARNINGS:\")\n    for issue in issues:\n        print(f\"   - {issue}\")\nelse:\n    print(\"CONVERGENCE FAILED:\")\n    for issue in issues:\n        print(f\"   - {issue}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Log final results to wandb\nif USE_WANDB:\n    wandb.log({\n        \"converged\": converged,\n        \"num_issues\": len(issues),\n        \"best_album_accuracy\": best_album_accuracy,\n        \"best_val_loss\": best_metrics.get(\"val_loss\", 0),\n        \"best_temporal_mode_accuracy\": best_metrics.get(\"temporal_mode_accuracy\", 0),\n        \"best_spatial_mode_accuracy\": best_metrics.get(\"spatial_mode_accuracy\", 0),\n        \"best_ontological_mode_accuracy\": best_metrics.get(\"ontological_mode_accuracy\", 0),\n    })\n    \n    # Log images\n    wandb.log({\"training_curves\": wandb.Image(\"/workspace/output/regression_training_curves.png\")})\n    \n    wandb.finish()\n    print(\"\\nResults logged to W&B\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save results summary\nimport json\n\nresults = {\n    \"task\": \"8.5 - Regression Convergence Validation\",\n    \"converged\": converged,\n    \"issues\": issues,\n    \"best_album_accuracy\": best_album_accuracy,\n    \"best_val_loss\": best_metrics.get(\"val_loss\", None),\n    \"best_metrics\": {k: float(v) if isinstance(v, (int, float, np.floating)) else v for k, v in best_metrics.items()},\n    \"epochs_trained\": len(history),\n    \"config\": CONFIG,\n}\n\nwith open(\"/workspace/output/regression_validation_results.json\", \"w\") as f:\n    json.dump(results, f, indent=2)\n\nprint(\"\\nResults saved to /workspace/output/regression_validation_results.json\")\nprint(\"\\nTask 8.5 Complete!\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
