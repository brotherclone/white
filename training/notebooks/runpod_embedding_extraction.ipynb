{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding Extraction for Phase 4 Training\n",
    "\n",
    "Extracts DeBERTa-v3-base embeddings for all segments.\n",
    "\n",
    "**Prerequisites:**\n",
    "- `/workspace/data/training_data_embedded.parquet` (or `base_manifest_db.parquet`)\n",
    "- GPU instance (RTX 4090 recommended)\n",
    "\n",
    "**Output:**\n",
    "- Parquet file with 768-dim `embedding` column added\n",
    "\n",
    "**Expected time:** ~5-10 minutes on RTX 4090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (safetensors avoids torch.load security issue)\n",
    "!pip install -q transformers pandas pyarrow tqdm sentencepiece tiktoken protobuf safetensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Embedding extraction will be slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Input file - try the large file first, fall back to base manifest\n",
    "INPUT_PATH = Path(\"/workspace/data/training_data_embedded.parquet\")\n",
    "if not INPUT_PATH.exists():\n",
    "    INPUT_PATH = Path(\"/workspace/data/base_manifest_db.parquet\")\n",
    "    \n",
    "OUTPUT_PATH = Path(\"/workspace/data/training_data_with_embeddings.parquet\")\n",
    "\n",
    "# Model - must match Phase 2 training\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "# Batch size - reduce if OOM\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Max sequence length\n",
    "MAX_LENGTH = 512\n",
    "\n",
    "print(f\"Input: {INPUT_PATH}\")\n",
    "print(f\"Output: {OUTPUT_PATH}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(f\"Loading {INPUT_PATH}...\")\n",
    "df = pd.read_parquet(INPUT_PATH)\n",
    "\n",
    "print(f\"Loaded {len(df)} segments\")\n",
    "print(f\"\\nColumns: {len(df.columns)}\")\n",
    "\n",
    "# Check if embeddings already exist\n",
    "if 'embedding' in df.columns:\n",
    "    print(\"\\nWARNING: 'embedding' column already exists!\")\n",
    "    print(f\"Shape: {df['embedding'].iloc[0].shape}\")\n",
    "    print(\"You may want to skip re-extraction.\")\n",
    "else:\n",
    "    print(\"\\nNo embeddings found - will extract.\")\n",
    "\n",
    "# Check rainbow columns\n",
    "rainbow_cols = [c for c in df.columns if 'rainbow_color' in c]\n",
    "print(f\"\\nRainbow columns: {rainbow_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine text column - prefer 'concept' over 'lyric_text'\n",
    "if 'concept' in df.columns and df['concept'].notna().sum() > 0:\n",
    "    text_col = 'concept'\n",
    "elif 'lyric_text' in df.columns:\n",
    "    text_col = 'lyric_text'\n",
    "else:\n",
    "    raise ValueError(\"No text column found!\")\n",
    "\n",
    "print(f\"Using text column: '{text_col}'\")\n",
    "\n",
    "# Get texts, replacing NaN with empty string\n",
    "texts = df[text_col].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "# Stats\n",
    "non_empty = sum(1 for t in texts if len(t.strip()) > 0)\n",
    "print(f\"Total texts: {len(texts)}\")\n",
    "print(f\"Non-empty: {non_empty}\")\n",
    "print(f\"Empty: {len(texts) - non_empty}\")\n",
    "\n",
    "# Preview\n",
    "print(\"\\nSample texts:\")\n",
    "for i in [0, len(texts)//2, -1]:\n",
    "    text = texts[i][:100] + \"...\" if len(texts[i]) > 100 else texts[i]\n",
    "    print(f\"  [{i}]: {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"\\nLoading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "print(\"Loading model (using safetensors)...\")\n",
    "# Use safetensors format to avoid torch.load security issue\n",
    "model = AutoModel.from_pretrained(MODEL_NAME, use_safetensors=True)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"\\nModel loaded!\")\n",
    "print(f\"Hidden size: {model.config.hidden_size}\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "embeddings = []\n",
    "num_batches = (len(texts) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "print(f\"Extracting embeddings for {len(texts)} texts in {num_batches} batches...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0, len(texts), BATCH_SIZE), desc=\"Extracting\"):\n",
    "        batch_texts = texts[i:i+BATCH_SIZE]\n",
    "        \n",
    "        # Tokenize\n",
    "        encoded = tokenizer(\n",
    "            batch_texts,\n",
    "            max_length=MAX_LENGTH,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        input_ids = encoded[\"input_ids\"].to(device)\n",
    "        attention_mask = encoded[\"attention_mask\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        # CLS token embedding (first token)\n",
    "        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        # Free GPU memory\n",
    "        del input_ids, attention_mask, outputs, batch_embeddings\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "print(f\"\\nExtracted {len(embeddings)} embeddings\")\n",
    "print(f\"Embedding shape: {embeddings[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Add Embeddings to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adding embeddings to dataframe...\")\n",
    "\n",
    "# Add as list of arrays (parquet-compatible)\n",
    "df['embedding'] = embeddings\n",
    "\n",
    "print(f\"DataFrame now has {len(df.columns)} columns\")\n",
    "print(f\"Embedding column dtype: {df['embedding'].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving to {OUTPUT_PATH}...\")\n",
    "\n",
    "# Ensure output directory exists\n",
    "OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save\n",
    "df.to_parquet(OUTPUT_PATH)\n",
    "\n",
    "# Check file size\n",
    "size_gb = OUTPUT_PATH.stat().st_size / (1024**3)\n",
    "print(f\"\\nSaved! File size: {size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Verify Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Verifying saved file...\")\n",
    "\n",
    "df_check = pd.read_parquet(OUTPUT_PATH)\n",
    "\n",
    "print(f\"Rows: {len(df_check)}\")\n",
    "print(f\"Columns: {len(df_check.columns)}\")\n",
    "print(f\"Has 'embedding': {'embedding' in df_check.columns}\")\n",
    "\n",
    "if 'embedding' in df_check.columns:\n",
    "    emb = df_check['embedding'].iloc[0]\n",
    "    print(f\"Embedding shape: {np.array(emb).shape}\")\n",
    "    print(f\"Embedding dtype: {np.array(emb).dtype}\")\n",
    "    print(f\"Embedding sample: {np.array(emb)[:5]}\")\n",
    "\n",
    "# Check rainbow columns preserved\n",
    "rainbow_cols = [c for c in df_check.columns if 'rainbow_color' in c]\n",
    "print(f\"\\nRainbow columns: {rainbow_cols}\")\n",
    "\n",
    "print(\"\\nVerification complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Rename Output (Optional)\n",
    "\n",
    "If you want to replace the original file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to rename\n",
    "# import shutil\n",
    "# \n",
    "# FINAL_PATH = Path(\"/workspace/data/training_data_embedded.parquet\")\n",
    "# BACKUP_PATH = Path(\"/workspace/data/training_data_no_embeddings.parquet\")\n",
    "# \n",
    "# # Backup original\n",
    "# if FINAL_PATH.exists():\n",
    "#     shutil.move(FINAL_PATH, BACKUP_PATH)\n",
    "#     print(f\"Backed up original to {BACKUP_PATH}\")\n",
    "# \n",
    "# # Rename new file\n",
    "# shutil.move(OUTPUT_PATH, FINAL_PATH)\n",
    "# print(f\"Renamed to {FINAL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"EMBEDDING EXTRACTION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\")\n",
    "print(f\"Input:  {INPUT_PATH}\")\n",
    "print(f\"Output: {OUTPUT_PATH}\")\n",
    "print(\"\")\n",
    "print(f\"Segments: {len(df)}\")\n",
    "print(\"Embedding dim: 768\")\n",
    "print(f\"File size: {size_gb:.2f} GB\")\n",
    "print(\"\")\n",
    "print(\"Next step: Run Phase 4 regression training\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}